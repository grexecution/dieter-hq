# CODING_RULES.md â€” Bluemonkeys Entwicklungsstandards

> Dieses File wird von allen AI-Agents gelesen bevor sie Code schreiben.
> Kopiere es in jedes Kundenprojekt-Root als `AGENTS.md` oder `CODING_RULES.md`.

---

## ğŸ¯ Oberste Regel

**QualitÃ¤t vor Geschwindigkeit.** Lieber 1 Feature das funktioniert als 5 die halb fertig sind.

---

## ğŸ“ Commit Standards

### Message Format
```
<type>: <kurze beschreibung>

[optionaler body mit details]
```

### Types
- `feat:` Neues Feature
- `fix:` Bugfix
- `refactor:` Code-Umbau ohne FunktionsÃ¤nderung
- `docs:` Dokumentation
- `chore:` Maintenance (deps, config)
- `test:` Tests

### âŒ VERBOTEN
- `fixed` ohne Kontext
- `wip` commits auf main
- Mehrere unrelated Changes in einem Commit

---

## ğŸ”’ Security

### NIEMALS committen:
- `.env` Files (nur `.env.example` mit Dummy-Werten)
- API Keys, Tokens, Passwords
- Datenbank-URLs mit Credentials
- Private Keys

### Vor jedem Push prÃ¼fen:
```bash
git diff --cached | grep -i "password\|secret\|token\|api_key"
```

---

## ğŸ—‚ï¸ Repo Hygiene

### In .gitignore (IMMER):
```
*.log
*.backup*
node_modules/
.next/
dist/
.env*
!.env.example
```

### NIEMALS im Repo:
- Log files
- Backup files (`.backup`, `.bak`, `.old`)
- Build artifacts
- AI-generierte Dokumentation die niemand liest

---

## ğŸ—ï¸ Code QualitÃ¤t

### Bevor du ein Feature "fertig" nennst:
1. âœ… Funktioniert der Happy Path?
2. âœ… Edge Cases behandelt?
3. âœ… Error Handling vorhanden?
4. âœ… TypeScript Errors = 0?
5. âœ… Keine `any` Types (auÃŸer wirklich nÃ¶tig)?
6. âœ… Console.logs entfernt?

### TODOs
- Jedes TODO braucht einen Kontext: `// TODO(greg): Implement rate limiting after MVP`
- Keine TODOs fÃ¼r kritische Features â€” entweder implementieren oder Issue erstellen

### Hardcoded Values
```typescript
// âŒ FALSCH
const apiUrl = 'https://api.example.com';

// âœ… RICHTIG
const apiUrl = process.env.API_URL;
```

---

## ğŸ§ª Testing

### Minimum Requirements:
- API Endpoints: Mindestens Happy Path Test
- Kritische Business Logic: Unit Tests
- Integrations: Smoke Tests

### Wenn kein Test:
Dokumentiere WARUM nicht und wie man manuell testet.

---

## ğŸ“– Dokumentation

### Was dokumentieren:
- README.md: Setup, Environment, wichtige Commands
- API Endpoints: Request/Response Format
- Komplexe Business Logic: Inline Kommentare

### Was NICHT dokumentieren:
- Offensichtliches (`// increment counter` vor `counter++`)
- AI-generierte Walls of Text die niemand liest

---

## ğŸ”„ Workflow

### Vor dem Coding:
1. Verstehe das Problem (frag nach wenn unklar)
2. Plan den Approach (kurz, nicht 10 Seiten)
3. Identifiziere Risiken

### WÃ¤hrend dem Coding:
1. Kleine, fokussierte Commits
2. Teste nach jedem signifikanten Change
3. Bei Problemen: erst debuggen, dann fragen

### Nach dem Coding:
1. Self-Review: WÃ¼rde ich diesen Code in 3 Monaten verstehen?
2. Cleanup: Console.logs, commented code, unused imports
3. Commit mit sinnvoller Message

---

## ğŸ¤– AI-Spezifisch

### Wenn du AI-generierten Code bekommst:
1. **LESEN** bevor committen
2. Verstehst du was es tut? Wenn nein â†’ nicht committen
3. Macht es Sinn fÃ¼r dieses Projekt? 
4. Keine Copy-Paste Walls of Code

### Subagents:
- Klare, spezifische Tasks
- Definiertes Scope
- Review das Ergebnis bevor merge

---

## ğŸš¨ Red Flags â€” Sofort stoppen und fragen:

- Mehr als 500 Zeilen in einem Commit
- Ã„nderungen an Auth/Payment/Security ohne expliziten Auftrag
- "Ich versteh nicht warum aber es funktioniert jetzt"
- Dependency Updates die Breaking Changes haben kÃ¶nnten

---

## ğŸ“ Kommunikation

- **Stuck > 15 min?** â†’ Frag nach
- **Unsicher ob Approach richtig?** â†’ Frag nach
- **Breaking Change nÃ¶tig?** â†’ Frag nach
- **Fertig?** â†’ Kurzes Summary was gemacht wurde

---

*Letzte Aktualisierung: 2026-02-05*
*Maintainer: Greg / Dieter*
